from pyspark.sql.functions import current_timestamp, col, lit, regexp_extract, from_json, schema_of_json
from pyspark.sql.types import StringType, StructType, StructField
import traceback

def update_source_metadata(tables_to_append, append_results, target_year, target_month):
    try:
        all_updated_metadata = []

        for table in tables_to_append:
            print(f"Processing metadata for table: {table}")
            
            # Construct the source table name
            source_table = f"{source_schema_name}.{table}"
            
            try:
                # Read source table
                source_df = spark.table(source_table)
                
                # Check if source_metadata column exists
                if "source_metadata" not in source_df.columns:
                    print(f"source_metadata column not found in table {source_table}")
                    continue
                
                # Define schema for source_metadata JSON
                metadata_schema = StructType([
                    StructField("file_name", StringType(), True),
                    StructField("file_path", StringType(), True),
                    StructField("file_size", StringType(), True)
                ])
                
                # Extract and parse source_metadata
                parsed_metadata = source_df.select(
                    from_json(col("source_metadata"), metadata_schema).alias("parsed_metadata")
                ).select("parsed_metadata.*")
                
                # Extract year and month from file_path
                filtered_metadata = parsed_metadata.withColumn(
                    "extracted_year", regexp_extract(col("file_path"), r"/(\d{4})/", 1)
                ).withColumn(
                    "extracted_month", regexp_extract(col("file_path"), r"/(\d{4})/(\d{2})/", 2)
                ).filter(
                    (col("extracted_year") == target_year) &
                    (col("extracted_month") == target_month)
                )
                
                if filtered_metadata.count() == 0:
                    print(f"No metadata found for table {table} in year {target_year}, month {target_month}")
                    continue
                
                # Get the process state for this table
                table_status = dict(append_results).get(table, "UNKNOWN")
                
                # Add new columns and transform existing ones
                updated_metadata = filtered_metadata.select(
                    lit(None).cast(StringType()).alias("id"),  # You may need to generate a unique ID here
                    lit("bk_mpo").alias("project_name"),
                    col("file_name"),
                    col("file_path"),
                    current_timestamp().alias("process_date"),
                    regexp_extract(col("file_name"), r"\.(\w+)$", 1).alias("file_type"),
                    lit(table_status).alias("file_process_state"),
                    current_timestamp().alias("process_start_dtm"),
                    current_timestamp().alias("process_end_dtm"),
                    col("file_size")
                )
                
                all_updated_metadata.append(updated_metadata)
                
            except Exception as table_error:
                print(f"Error processing table {table}: {str(table_error)}")
                continue
        
        # Combine all updated metadata
        if not all_updated_metadata:
            print("No metadata found for any tables")
            return
        
        combined_metadata = all_updated_metadata[0]
        for df in all_updated_metadata[1:]:
            combined_metadata = combined_metadata.union(df)
        
        # Define the target table
        target_table_path = f"{target_metadata_schema}.{target_metadata_table}"
        
        # Append the updated metadata to the target table
        combined_metadata.write.mode("append").saveAsTable(target_table_path)
        
        # Log processing results
        print(f"Metadata updated in {target_table_path}")
        print(f"Total number of records processed: {combined_metadata.count()}")
        
        # Log status for each table
        for table, status in append_results:
            print(f"Table {table}: {status}")
        
    except Exception as e:
        error_message = f"Error updating metadata: {str(e)}\n{traceback.format_exc()}"
        print(error_message)
        raise

# Example usage remains the same as before
