# Import necessary libraries
from databricks import notebook

# Define the parameters
param_names = [
    "tables_to_append",
    "source_schema",
    "target_schema",
    "source_metadata_table",
    "target_metadata_schema",
    "target_metadata_table",
    "target_month",
    "target_year"
]

# Create input widgets for each parameter
for param in param_names:
    dbutils.widgets.text(param, "", f"Enter {param}")

# Function to run the notebook
def run_master_append_job():
    # Get the values from the widgets
    params = {param: dbutils.widgets.get(param) for param in param_names}
    
    # Convert tables_to_append to a list
    params["tables_to_append"] = params["tables_to_append"].split(',')
    
    # Path to your original notebook
    notebook_path = "/path/to/your/1.MASTER_APPEND_OPERATION"
    
    # Run the notebook and capture the output
    output = notebook.run(notebook_path, timeout_seconds=0, arguments=params)
    
    return output

# Run the job and print the output
result = run_master_append_job()
print(f"Job Output: {result}")

# You can add more code here to process the result if needed

# Optional: Remove widgets after execution
for param in param_names:
    dbutils.widgets.remove(param)
