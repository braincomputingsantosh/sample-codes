import sqlite3
import csv
import os
import glob
import chardet

def create_connection():
    conn = sqlite3.connect('dc_census_sf1.db')
    return conn

def create_table(conn):
    cursor = conn.cursor()
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS dc_census_data (
        file_id INTEGER,
        year INTEGER,
        sftype TEXT,
        state TEXT,
        col1 INTEGER,
        segment INTEGER,
        logrecno INTEGER,
        tbl TEXT,
        stat REAL
    )
    ''')
    conn.commit()

def safe_int(value, default=0):
    try:
        return int(value)
    except (ValueError, TypeError):
        return default

def detect_encoding(file_path):
    with open(file_path, 'rb') as file:
        raw_data = file.read()
    return chardet.detect(raw_data)['encoding']

def process_sf1_file(file_path, conn, file_id):
    encoding = detect_encoding(file_path)
    with open(file_path, 'r', encoding=encoding, errors='replace') as file:
        reader = csv.reader(file)
        cursor = conn.cursor()
        
        for row_num, row in enumerate(reader, start=1):
            if len(row) < 6:
                print(f"Skipping row {row_num} due to insufficient columns: {row}")
                continue

            sftype = row[0] if len(row) > 0 else ''
            state = 'DC'  # Since we're focusing on DC
            col1 = safe_int(row[3] if len(row) > 3 else 0)
            segment = safe_int(row[4] if len(row) > 4 else 0)
            logrecno = safe_int(row[5] if len(row) > 5 else 0)
            
            year = 2010  # Assuming 2010 Census, change if different
            
            # Process the data columns (assuming they start from index 6)
            for i, value in enumerate(row[6:], start=1):
                tbl = f'SF1_{i:04d}'  # Creating a table name for each column
                try:
                    stat = float(value) if value.strip() else None
                except ValueError:
                    print(f"Invalid numeric value in file {file_path}, row {row_num}, column {i+6}: {value}")
                    stat = None
                
                cursor.execute('''
                INSERT INTO dc_census_data 
                (file_id, year, sftype, state, col1, segment, logrecno, tbl, stat)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (file_id, year, sftype, state, col1, segment, logrecno, tbl, stat))
        
        conn.commit()

def main():
    conn = create_connection()
    create_table(conn)
    
    data_directory = 'dc_sf1_data'
    
    file_id = 62541  # Starting file_id
    
    for file_path in glob.glob(os.path.join(data_directory, '*.sf1')):
        print(f"Processing file: {file_path}")
        process_sf1_file(file_path, conn, file_id)
        file_id += 1  # Increment file_id for the next file
    
    conn.close()
    print("Data processing complete.")

if __name__ == "__main__":
    main()
