import json
from pyspark.sql import SparkSession
import os

# Initialize Spark session
spark = SparkSession.builder.appName("ListFiles").getOrCreate()

# Define the folder path and output file path
folder_path = "/path/to/your/folder"
output_path = "/dbfs/path/to/output/folder/key_value_pairs.json"

def process_filename(file_name):
    # Remove 'STRUCTURE_' prefix if present
    if file_name.startswith("STRUCTURE_"):
        file_name = file_name[len("STRUCTURE_"):]

    # Remove '_COUNT' or '_INCR' suffix if present
    if file_name.endswith("_COUNT") or file_name.endswith("_INCR"):
        file_name = file_name.rsplit('_', 1)[0]

    return file_name

# List files in the folder and create key-value pairs
file_list = dbutils.fs.ls(folder_path)
key_value_pairs = {os.path.basename(file_info.path): process_filename(os.path.splitext(os.path.basename(file_info.path))[0]) for file_info in file_list}

# Convert the dictionary to JSON format
json_data = json.dumps(key_value_pairs, indent=4)

# Write the JSON data to a file in DBFS
with open(output_path, 'w') as file:
    file.write(json_data)

print(f"Key-value pairs have been written to {output_path}")

# Stop the Spark session
spark.stop()
