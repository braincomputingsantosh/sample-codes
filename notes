from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, when

def compare_tables(table1_name, table2_name, key_columns):
    spark = SparkSession.builder.getOrCreate()
    
    # Read both tables
    df1 = spark.table(table1_name)
    df2 = spark.table(table2_name)
    
    # Identify all columns
    all_columns = list(set(df1.columns + df2.columns))
    
    # Full outer join
    joined_df = df1.select(all_columns).join(
        df2.select(all_columns),
        key_columns,
        "full_outer"
    )
    
    # Calculate differences
    diff_df = joined_df.select(
        *[when(col(f"{c}_1").isNull() & col(f"{c}_2").isNotNull(), "Missing in Table1")
          .when(col(f"{c}_1").isNotNull() & col(f"{c}_2").isNull(), "Missing in Table2")
          .when(col(f"{c}_1") != col(f"{c}_2"), "Value Mismatch")
          .otherwise("Match").alias(c)
        for c in all_columns if c not in key_columns]
    )
    
    # Generate report
    report = diff_df.agg(*[
        count(when(col(c) != "Match", c)).alias(f"{c}_diff_count")
        for c in diff_df.columns
    ])
    
    # Add total row counts
    report = report.withColumn("Table1_row_count", count("*").over())
    report = report.withColumn("Table2_row_count", count("*").over())
    
    return report

# Usage example
table1_name = "database1.table1"
table2_name = "database2.table2"
key_columns = ["id", "date"]  # Replace with your actual key columns

report_df = compare_tables(table1_name, table2_name, key_columns)
report_df.show()

# Optionally, save the report
report_df.write.mode("overwrite").saveAsTable("database.comparison_report")
