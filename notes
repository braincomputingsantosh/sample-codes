from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit

# Create a SparkSession (this is usually pre-created in Databricks notebooks)
spark = SparkSession.builder.appName("MultiUserTempTableSimulation").getOrCreate()

# Create a global temporary view
spark.sql("""
CREATE GLOBAL TEMPORARY VIEW global_temp.Temp_InstitutionsList AS
SELECT 1 as id, 'University A' as name
UNION ALL
SELECT 2 as id, 'University B' as name
""")

# Function to simulate a user interacting with the global temp view
def simulate_user(user_id):
    print(f"User {user_id} accessing the global temporary view:")
    
    # Read from the global temporary view
    df = spark.sql("SELECT * FROM global_temp.Temp_InstitutionsList")
    df.show()
    
    # Simulate adding data (note: this doesn't actually modify the view for other users)
    new_data = spark.createDataFrame([(3, f"University {user_id}")], ["id", "name"])
    combined_df = df.union(new_data)
    
    print(f"User {user_id} after adding data (local to this session):")
    combined_df.show()

# Simulate multiple users
simulate_user("A")
simulate_user("B")

# Check the original global temporary view
print("Original global temporary view remains unchanged:")
spark.sql("SELECT * FROM global_temp.Temp_InstitutionsList").show()

# Clean up
spark.sql("DROP VIEW global_temp.Temp_InstitutionsList")
