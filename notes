from pyspark.sql.functions import col, input_file_name, udf
from pyspark.sql.types import BinaryType, StringType, ArrayType, StructType, StructField
import zipfile
from io import BytesIO

def check_and_unzip_file(s3_bucket_path, zip_file_name, extract_path):
    full_zip_path = f"{s3_bucket_path}/{zip_file_name}"
    
    # Check if the file exists
    if len(dbutils.fs.ls(full_zip_path)) > 0:
        print(f"The file '{zip_file_name}' exists in the S3 bucket at '{s3_bucket_path}'.")
        
        # Read the file as a binary file
        df = (spark.read.format("binaryFile")
              .option("pathGlobFilter", zip_file_name)
              .load(s3_bucket_path)
              .select(col("content"), input_file_name().alias("file_name")))

        # Define UDF to process zip content
        @udf(returnType=ArrayType(StructType([
            StructField("file_path", StringType()),
            StructField("content", BinaryType())
        ])))
        def process_zip_content(content):
            zip_content = BytesIO(content)
            result = []
            with zipfile.ZipFile(zip_content) as zip_ref:
                for file in zip_ref.namelist():
                    extracted_content = zip_ref.read(file)
                    result.append((f"{extract_path}/{file}", extracted_content))
            return result

        # Apply UDF
        extracted_files_df = df.withColumn("extracted_files", process_zip_content("content"))

        # Collect the results and write files
        for row in extracted_files_df.collect():
            for file_path, content in row.extracted_files:
                dbutils.fs.put(file_path, content, overwrite=True)
        
        print(f"Successfully unzipped '{zip_file_name}' to '{extract_path}'.")
    else:
        print(f"The file '{zip_file_name}' does not exist in the S3 bucket at '{s3_bucket_path}'.")

# Example usage
s3_bucket_path = "s3a://your-bucket-name/your/path"
zip_file_name = "your_large_zip_file.zip"
extract_path = "s3a://your-bucket-name/your/extract/path"

check_and_unzip_file(s3_bucket_path, zip_file_name, extract_path)
