# HELOC Exam Process Task Requirements

## 1. Overview
Enhance the existing data append function to prevent duplicate entries in the target table based on year and month, and update specific columns in the target table.

## 2. Functional Requirements

2.1. Source Data Extraction
- Extract the file path from the `source_metadata` JSON column in the source table (bk_mpo_raw).
- Parse the year and month from the file path (format: /Volumes/staging/bkmpo/raw/YYYY/MM/filename.csv).

2.2. Target Table Verification
- Check if data for the extracted year and month already exists in the target table.
- The target table must have 'year' and 'month' columns for comparison.

2.3. Conditional Data Append
- If data for the specific year and month does not exist in the target table, append the new data.
- If data already exists, do not append and proceed to update specific columns.

2.4. Target Table Update
- For the HELOC target table, update the following columns:
  - `ingest_time`: Set to the current timestamp when the operation is performed.
  - `file_path`: Update with the file path of the source data being processed.

2.5. Logging and Reporting
- Log the result of each operation (PROCESSED or FAILED).
- For PROCESSED results, include details of the updated `ingest_time` and `file_path`.
- Provide detailed error messages in case of failures.

## 3. Technical Requirements

3.1. Use PySpark for data processing.
3.2. Implement error handling and exception reporting.
3.3. Ensure compatibility with the existing Databricks environment.

## 4. Performance Considerations

4.1. Optimize the data existence check to minimize processing time.
4.2. Consider the impact on overall ETL pipeline performance.
4.3. Ensure efficient updating of `ingest_time` and `file_path` columns in the target table.





-------- Code ---------

from pyspark.sql.functions import col, current_timestamp, from_json
from pyspark.sql.types import StructType, StringType, TimestampType
import re

def append_and_update_metadata(table_name):
    try:
        # Construct full table names
        source_table = f"{source_schema_name}.{table_name}"
        target_table = f"{target_schema_name}.{table_name}"
        
        # Read the source table
        source_df = spark.table(source_table)
        
        # Extract file_path from source_metadata
        file_path = source_df.select(col("source_metadata.file_path")).first()[0]
        
        # Extract year and month from file_path
        year_month_match = re.search(r'/(\d{4})/(\d{2})/', file_path)
        if year_month_match:
            year, month = year_month_match.groups()
        else:
            raise ValueError("Year and month not found in file path")
        
        # Check if data for this year and month exists in target table
        target_df = spark.table(target_table)
        existing_data = target_df.filter((col("year") == year) & (col("month") == month))
        
        if existing_data.count() == 0:
            # Data doesn't exist, proceed with append
            # Add file_path and ingest_time columns
            source_df = source_df.withColumn("file_path", col("source_metadata.file_path")) \
                                 .withColumn("ingest_time", current_timestamp())
            
            # Select all columns except source_metadata for appending
            columns_to_append = [col for col in source_df.columns if col != "source_metadata"]
            
            # Append the data to the target table
            source_df.select(columns_to_append).write.mode("append").saveAsTable(target_table)
            
            print(f"Append operation completed for {table_name}")
            print(f"Source: {source_table}")
            print(f"Target: {target_table}")
            print(f"Appended data for year {year} and month {month}")
            return "PROCESSED"
        else:
            # Data exists, update file_path and ingest_time
            target_df.filter((col("year") == year) & (col("month") == month)) \
                     .update({"file_path": file_path, "ingest_time": current_timestamp()})
            
            print(f"Data for year {year} and month {month} already exists in {target_table}. Updated metadata.")
            return "PROCESSED"
        
    except Exception as e:
        error_message = f"Error appending {table_name}: {str(e)}\n{traceback.format_exc()}"
        print(error_message)
        return "FAILED"
