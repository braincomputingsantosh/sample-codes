def append_and_update_metadata(raw_table_name, silver_table_name, as_of_month):
    try:
        # Construct full table names
        raw_table = f"bk_mpo_raw.{raw_table_name}"
        silver_table = f"bk_mpo_silver.{silver_table_name}"
        
        # Read the raw table
        raw_df = spark.table(raw_table)
        
        # Extract file_path from source_metadata in the raw table
        file_path = raw_df.filter(col("as_of_month") == as_of_month) \
                          .select(col("source_metadata.file_path")).first()[0]
        print(f"file_path——>", file_path)
        
        # Check if data for this as_of_month exists in silver table
        silver_df = spark.table(silver_table)
        existing_data = silver_df.filter(col("as_of_month") == as_of_month)
        
        if existing_data.count() == 0:
            # Data doesn't exist in silver table, proceed with append
            # Prepare data for silver table (excluding source_metadata)
            columns_to_append = [col for col in raw_df.columns if col != "source_metadata"]
            data_to_append = raw_df.filter(col("as_of_month") == as_of_month) \
                                   .select(columns_to_append) \
                                   .withColumn("file_path", lit(file_path)) \
                                   .withColumn("ingest_time", current_timestamp())
            
            # Append the data to the silver table
            data_to_append.write.mode("append").saveAsTable(silver_table)
            
            print(f"Append operation completed for {silver_table_name}")
            print(f"Source: {raw_table}")
            print(f"Target: {silver_table}")
            print(f"Appended data for as_of_month {as_of_month}")
            return "PROCESSED"
        else:
            # Data exists in silver table, update file_path and ingest_time
            silver_df.filter(col("as_of_month") == as_of_month) \
                     .update({"file_path": file_path, "ingest_time": current_timestamp()})
            
            print(f"Data for as_of_month {as_of_month} already exists in {silver_table}. Updated metadata.")
            process_and_update_metadata(spark, metadata_table_name, file_path, silver_table_name, "PROCESSED", 0, "false")
            return "PROCESSED"
    
    except Exception as e:
        error_message = f"Error processing {raw_table_name} to {silver_table_name}: {str(e)}\n{traceback.format_exc()}"
        process_and_update_metadata(spark, metadata_table_name, file_path, silver_table_name, "FAILED", 0, "true")
        print(error_message)
        return "FAILED"

# Function to process the table
def process_table(raw_table_name, silver_table_name):
    # Execute the EXCEPT query
    diff_df = spark.sql(f"""
    SELECT as_of_month FROM bk_mpo_raw.{raw_table_name}
    EXCEPT
    SELECT as_of_month FROM bk_mpo_silver.{silver_table_name}
    """)
    
    # Get the list of as_of_month values to process
    as_of_months_to_process = [row.as_of_month for row in diff_df.collect()]
    
    results = []
    for as_of_month in as_of_months_to_process:
        result = append_and_update_metadata(raw_table_name, silver_table_name, as_of_month)
        results.append((as_of_month, result))
    
    return results

# Example usage
raw_table_name = "heloc"
silver_table_name = "heloc"
processing_results = process_table(raw_table_name, silver_table_name)

for as_of_month, result in processing_results:
    print(f"as_of_month: {as_of_month}, Result: {result}")
