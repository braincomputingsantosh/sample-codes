import os
from pyspark.dbutils import DBUtils

def check_file_in_volume(volume_name, file_path):
    # Create a DBUtils object
    dbutils = DBUtils()
    
    # Construct the full path to the file in the volume
    full_path = f"/dbfs/mnt/{volume_name}/{file_path}"
    
    # Check if the file exists
    if os.path.exists(full_path):
        print(f"The file '{file_path}' exists in the volume '{volume_name}'.")
    else:
        print(f"The file '{file_path}' does not exist in the volume '{volume_name}'.")

# Example usage
volume_name = "your_volume_name"
file_path = "path/to/your/file.txt"

check_file_in_volume(volume_name, file_path)


import boto3
from botocore.exceptions import ClientError

def check_file_in_s3(bucket_name, file_key):
    # Create an S3 client
    s3 = boto3.client('s3')
    
    try:
        # Try to get the object's metadata
        s3.head_object(Bucket=bucket_name, Key=file_key)
        print(f"The file '{file_key}' exists in the S3 bucket '{bucket_name}'.")
    except ClientError as e:
        if e.response['Error']['Code'] == '404':
            print(f"The file '{file_key}' does not exist in the S3 bucket '{bucket_name}'.")
        else:
            print(f"An error occurred while checking for the file: {e}")

# Example usage
bucket_name = 'your-bucket-name'
file_key = 'path/to/your/file.txt'

check_file_in_s3(bucket_name, file_key)


import boto3
from botocore.exceptions import ClientError, ParamValidationError

def check_file_in_s3(bucket_name, file_key):
    # Create an S3 client
    s3 = boto3.client('s3')
    
    try:
        # Try to get the object's metadata
        s3.head_object(Bucket=bucket_name, Key=file_key)
        print(f"The file '{file_key}' exists in the S3 bucket '{bucket_name}'.")
    except ClientError as e:
        if e.response['Error']['Code'] == '404':
            print(f"The file '{file_key}' does not exist in the S3 bucket '{bucket_name}'.")
        else:
            print(f"An error occurred while checking for the file: {e}")
    except ParamValidationError as e:
        print(f"Parameter validation error: {e}")
        print("Please check that your bucket_name and file_key are correctly formatted.")

# Example usage
bucket_name = 'your-bucket-name'
file_key = 'path/to/your/file.txt'

check_file_in_s3(bucket_name, file_key)


def check_file_in_s3(mount_point, file_path):
    full_path = f"{mount_point}/{file_path}"
    
    if dbutils.fs.ls(mount_point):  # Check if the mount point exists
        if dbutils.fs.ls(full_path):
            print(f"The file '{file_path}' exists in the mounted S3 bucket at '{mount_point}'.")
        else:
            print(f"The file '{file_path}' does not exist in the mounted S3 bucket at '{mount_point}'.")
    else:
        print(f"The mount point '{mount_point}' does not exist. Please check your S3 bucket mounting.")

# Example usage
mount_point = "/mnt/your-s3-mount"
file_path = "path/to/your/file.txt"

check_file_in_s3(mount_point, file_path)


import zipfile
import io
from pyspark.dbutils import DBUtils

def check_and_unzip_file(volume_path, zip_file_name, extract_path):
    dbutils = DBUtils()
    full_zip_path = f"{volume_path}/{zip_file_name}"
    
    # Check if the file exists
    if dbutils.fs.ls(full_zip_path):
        print(f"The file '{zip_file_name}' exists in the volume at '{volume_path}'.")
        
        # Read the zip file
        with io.BytesIO(dbutils.fs.read(full_zip_path, -1)) as zip_buffer:
            # Open the zip file
            with zipfile.ZipFile(zip_buffer) as zip_ref:
                # Extract all contents
                for file in zip_ref.namelist():
                    content = zip_ref.read(file)
                    extract_file_path = f"{extract_path}/{file}"
                    dbutils.fs.put(extract_file_path, content, overwrite=True)
        
        print(f"Successfully unzipped '{zip_file_name}' to '{extract_path}'.")
    else:
        print(f"The file '{zip_file_name}' does not exist in the volume at '{volume_path}'.")

# Example usage
volume_path = "/Volumes/staging/bk_hpi_raw/hpi_landing"
zip_file_name = "your_zip_file.zip"
extract_path = "/Volumes/staging/bk_hpi_raw/hpi_extracted"

check_and_unzip_file(volume_path, zip_file_name, extract_path)
