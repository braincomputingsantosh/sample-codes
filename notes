from pyspark.sql import SparkSession
from pyspark.sql.functions import col, md5

def compare_databases(spark, db1_name, db2_name, table_name):
  """
  Compares two databases in Databricks based on a given table name.

  Args:
    spark: SparkSession object.
    db1_name: Name of the first database (e.g., "census.acs").
    db2_name: Name of the second database (e.g., "staging.census.acs_2022").
    table_name: Name of the table to compare in both databases.

  Returns:
    A DataFrame showing the differences between the two tables, if any.
  """

  # Read the tables from both databases
  df1 = spark.table(f"{db1_name}.{table_name}")
  df2 = spark.table(f"{db2_name}.{table_name}")

  # Calculate hash of all columns for each row to efficiently compare
  df1 = df1.withColumn("row_hash", md5(*df1.columns))
  df2 = df2.withColumn("row_hash", md5(*df2.columns))

  # Find rows that are in df1 but not in df2
  df1_only = df1.select("row_hash").subtract(df2.select("row_hash"))
  df1_diff = df1.join(df1_only, "row_hash", "left_semi")

  # Find rows that are in df2 but not in df1
  df2_only = df2.select("row_hash").subtract(df1.select("row_hash"))
  df2_diff = df2.join(df2_only, "row_hash", "left_semi")

  # Union the differences
  all_diffs = df1_diff.union(df2_diff)

  return all_diffs

# Initialize SparkSession
spark = SparkSession.builder.appName("DatabaseComparison").getOrCreate()

# Set database and table names
db1_name = "census.acs"
db2_name = "staging.census.acs_2022"
table_name = "your_table_name"  # Replace with the actual table name

# Compare the databases
diff_df = compare_databases(spark, db1_name, db2_name, table_name)

# Show the differences
diff_df.show()

# Stop the SparkSession
spark.stop()
