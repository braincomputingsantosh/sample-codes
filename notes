# Import necessary libraries
import json
from databricks import notebook

# Set up the parameters
params = {
    "tables_to_append": "heloc,loan_amount,loan_month_loss_mit",
    "source_schema": "bk_mpo_raw",
    "target_schema": "test_bk_mpo",
    "source_metadata_table": "source_metadata_new",
    "target_metadata_schema": "test_bk_mpo",
    "target_metadata_table": "source_metadata_new",
    "target_month": "04",
    "target_year": "2024"
}

# Create widgets for each parameter
for key, value in params.items():
    dbutils.widgets.text(key, value)

# Function to run the notebook
def run_master_append_job():
    # Get the values from the widgets
    params = {key: dbutils.widgets.get(key) for key in params.keys()}
    
    # Convert tables_to_append to a list
    params["tables_to_append"] = params["tables_to_append"].split(',')
    
    # Path to your original notebook
    notebook_path = "/path/to/your/1.MASTER_APPEND_OPERATION"
    
    # Run the notebook and capture the output
    output = notebook.run(notebook_path, timeout_seconds=0, arguments=params)
    
    return output

# Run the job and print the output
result = run_master_append_job()
print(f"Job Output: {result}")

# You can add more code here to process the result if needed
