from pyspark.sql import SparkSession
from pyspark.sql.functions import col, md5

def compare_databases_different_tables(spark, db1_name, db2_name, table1_name, table2_name):
  """
  Compares two databases in Databricks with different table names.

  Args:
    spark: SparkSession object.
    db1_name: Name of the first database.
    db2_name: Name of the second database.
    table1_name: Name of the table in the first database.
    table2_name: Name of the table in the second database.

  Returns:
    A DataFrame showing the differences between the two tables, if any.
  """

  # Read the tables from both databases using their respective names
  df1 = spark.table(f"{db1_name}.{table1_name}")
  df2 = spark.table(f"{db2_name}.{table2_name}")

  # Calculate hash of all columns for each row
  df1 = df1.withColumn("row_hash", md5(*df1.columns))
  df2 = df2.withColumn("row_hash", md5(*df2.columns))

  # Find rows that are in df1 but not in df2
  df1_only = df1.select("row_hash").subtract(df2.select("row_hash"))
  df1_diff = df1.join(df1_only, "row_hash", "left_semi")

  # Find rows that are in df2 but not in df1
  df2_only = df2.select("row_hash").subtract(df1.select("row_hash"))
  df2_diff = df2.join(df2_only, "row_hash", "left_semi")

  # Union the differences
  all_diffs = df1_diff.union(df2_diff)

  return all_diffs

# Initialize SparkSession
spark = SparkSession.builder.appName("DatabaseComparison").getOrCreate()

# Set database and table names
db1_name = "census.acs"
db2_name = "staging.census.acs_2022"
table1_name = "your_table_1_name"  # Replace with the actual table name in db1
table2_name = "your_table_2_name"  # Replace with the actual table name in db2

# Compare the databases with different table names
diff_df = compare_databases_different_tables(spark, db1_name, db2_name, table1_name, table2_name)

# Show the differences
diff_df.show()

# Stop the SparkSession
spark.stop()
